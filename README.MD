![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![pdfplumber](https://img.shields.io/badge/pdfplumber-FF5A5F?style=for-the-badge&logo=&logoColor=white)
![Zipfile](https://img.shields.io/badge/Zipfile-BDBDBD?style=for-the-badge&logo=&logoColor=black)
# Teste de Transforma√ß√£o de Dados

Este projeto tem como objetivo transformar os dados do PDF do Anexo I (obtido no **[Teste de Web Scraping](https://github.com/Victor-Saraiva-P/teste-web-scraping))** em uma tabela estruturada.

## Stack Utilizada

- **Linguagem:** Python 3
- **Bibliotecas:**
  - `pdfplumber` ‚Äì Para extra√ß√£o dos dados da tabela no PDF.
  - `pandas` ‚Äì Para manipula√ß√£o dos dados e cria√ß√£o da tabela.
  - `zipfile` ‚Äì Biblioteca padr√£o do Python para compacta√ß√£o de arquivos.
- **Outros reposit√≥rios**
    - uma adapta√ß√£o de [Teste de Web Scraping](https://github.com/Victor-Saraiva-P/teste-web-scraping)

  ## Funcionalidades

- **Extra√ß√£o dos Dados do PDF:**  
  Utiliza `pdfplumber` para ler todas as p√°ginas do PDF do Anexo I e extrair a tabela com os dados de procedimentos e eventos em sa√∫de.

- **Transforma√ß√£o dos Dados:**  
  Organiza os dados extra√≠dos em um DataFrame do Pandas, realizando limpeza e formata√ß√£o dos dados, e substitui as abrevia√ß√µes das colunas OD e AMB por suas descri√ß√µes completas (segundo a legenda no rodap√© do PDF).

- **Exporta√ß√£o e Compacta√ß√£o:**  
  Salva o DataFrame resultante em formato CSV e, em seguida, compacta o CSV em um arquivo ZIP com o nome `Teste_{seu_nome}.zip`.

- **Logging Detalhado:**  
  O sistema registra o andamento de cada etapa para facilitar o monitoramento e a depura√ß√£o.
## Estrutura do Projeto

- `downloads` ‚Äì Pasta onde ser√£o salvos o PDF do Anexo I (em /arquivos) e o arquivo compactado
- `web_scraping` ‚Äì C√≥pia adaptada do c√≥digo de web scraping original
- `web_scraping_config.py` ‚Äì Configura√ß√µes espec√≠ficas do web scraping (adaptadas para Anexo I).
## Rodando Localmente

1. **Clone o Reposit√≥rio:**

   ```bash
   git clone https://github.com/seu-usuario/teste-transformacao-dados.git
   cd teste-transformacao-dados
   ```

2. **Crie um Ambiente Virtual e Instale as Depend√™ncias:**

   ```bash
   python -m venv venv
   source venv/bin/activate  # No Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **Configure o Sistema (Opcional):**  
   Edite `config.py` se precisar ajustar os caminhos, nomes de arquivo ou outros par√¢metros.

4. **Execute o Script:**

   ```bash
   python transformador.py
   ```

5. **Verifique os Resultados:**

   - O CSV com os dados transformados ser√° salvo no diret√≥rio configurado.
   - O arquivo compactado `Teste_{seu_nome}.zip` ser√° gerado conforme o especificado.
   - Consulte os logs para acompanhar o andamento do processo.
## üë®‚Äçüíª Autor

Desenvolvido por **[Victor Saraiva](https://github.com/Victor-Saraiva-P)**
